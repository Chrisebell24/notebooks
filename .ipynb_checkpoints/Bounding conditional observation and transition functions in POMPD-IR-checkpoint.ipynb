{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are POMPD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POMPD stands for Partially Observable Markov Decision Process. In rough terms a POMDP is a Markov Decision Process in which the agent does not have absolute confidence of the underlying state of the world. The agent makes observations to update its model of the state of the world. However there is also uncertainty in the observations made by the agent.\n",
    "\n",
    "The previous is formalized in the following way:\n",
    "\n",
    "## put the formalization!!!\n",
    "\n",
    "On the mathematical formulation of POMDP, there are two important sets which are derived from conditional probabilities. \n",
    "\n",
    "One is the set of observations the agent makes to derive its current state, which is treated as a conditional probabilities given the state in which the agent believes it has transitioned into, and the action taken to go to that state:\n",
    "\n",
    "$$ \\bf{O}(\\bf{o | s', a}) $$\n",
    "\n",
    "Another is the set of transition probabilities between states. When the agent takes an action $a \\in \\bf{A}$, the environment transitions to a state (or to a possible set of states?) $\\bf{s}'$ with probability $\\bf{t \\in T}$, for:\n",
    "\n",
    "$$ \\bf{T}(\\bf{s' | s,a}) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is it useful to bound observation and transition functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution to a POMDP is called an *optimal policy*, noted with $pi^*$. Depending on how we choose to treat this problem, the optimal policy is often a function related to $\\bf{O}$ and $\\bf{T}$.\n",
    "\n",
    "\n",
    "For many practical applications it is already challenging enough to model the actions and states in terms of probabilities. Building conditional distributions on top of that makes POMDPs especially challenging. As a consequence, sampling technique, generalization techniques and heuristics are often used when solving POMDPs. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we intend to bound conditional functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
